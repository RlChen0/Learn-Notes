{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Example of printing call method input and output shapes",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RlChen0/Learn-Notes/blob/master/Example_of_printing_call_method_input_and_output_shapes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow dm-sonnet 2>/dev/null"
      ],
      "metadata": {
        "id": "kErGYsCvYMn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tu0peLFXz7w"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import sonnet as snt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following utilities can be used to wrap modules in order to make them print their input and output shape (on `__call__`methods):"
      ],
      "metadata": {
        "id": "LGWgdpUnbppn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "\n",
        "def stringify(leaf):\n",
        "  if isinstance(leaf, tf.Tensor):\n",
        "    leaf = f'{leaf.dtype.name}[{\",\".join(map(str, leaf.shape))}]'\n",
        "  return str(leaf)\n",
        "\n",
        "def print_shape(f):\n",
        "  @functools.wraps(f)\n",
        "  def wrapper(self, *args, **kwargs):\n",
        "    cls_name = self.__class__.__name__\n",
        "    args_str = list(tf.nest.map_structure(stringify, args))\n",
        "    args_str.extend([f'{k}={tf.nest.map_structure(stringify, v)}' for k, v in kwargs.items()])\n",
        "    out = f(self, *args, **kwargs)\n",
        "    ret_str = tf.nest.map_structure(stringify, out)\n",
        "    print(f'{(\"{}({})\".format(self.name, \", \".join(args_str))):60} -> {ret_str}')\n",
        "    return out\n",
        "  return wrapper\n",
        "\n",
        "def patch_modules_to_print_shape():\n",
        "  for cls in snt.Module.__subclasses__():\n",
        "    if hasattr(cls, \"__call__\"):\n",
        "      before = getattr(cls.__call__, '__mtps_before', cls.__call__)\n",
        "      cls.__call__ = print_shape(before)\n",
        "      cls.__call__.__mtps_before = before"
      ],
      "metadata": {
        "id": "_N6YnZV7beXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It works with custom types:"
      ],
      "metadata": {
        "id": "NqsKNaiJbv8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModule(snt.Module):\n",
        "  def __call__(self, x, *, reshape: bool):\n",
        "    if reshape:\n",
        "      x = tf.reshape(x, [1] + x.shape)\n",
        "    return x\n",
        "\n",
        "# Call this after you have defined all your subclasses..\n",
        "patch_modules_to_print_shape()\n",
        "\n",
        "m = MyModule()\n",
        "x = tf.ones([1, 1])\n",
        "_ = m(x, reshape=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ6ggxntX3VI",
        "outputId": "acaaf068-0c8e-47aa-8ac5-77d00d19d847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my_module(float32[1,1], reshape=True)                        -> float32[1,1,1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or with builtin ones:"
      ],
      "metadata": {
        "id": "1gPZ9TXCbx_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.ones([1, 28 * 28])\n",
        "m = snt.nets.MLP([300, 100, 10])\n",
        "_ = m(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-43bT_MIdSA1",
        "outputId": "a05a0b85-b571-4bcb-88c9-7bf0d75c63a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linear_0(float32[1,784])                                     -> float32[1,300]\n",
            "linear_1(float32[1,300])                                     -> float32[1,100]\n",
            "linear_2(float32[1,100])                                     -> float32[1,10]\n",
            "mlp(float32[1,784])                                          -> float32[1,10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.ones([1, 224, 224, 3])\n",
        "m = snt.nets.ResNet50(1000)\n",
        "_ = m(x, is_training=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cq6Xb6bblH6",
        "outputId": "c3109dba-456e-4a9e-8975-00683de9afe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial_conv(float32[1,224,224,3])                           -> float32[1,112,112,64]\n",
            "initial_batchnorm(float32[1,112,112,64], is_training=True)   -> float32[1,112,112,64]\n",
            "shortcut_conv(float32[1,56,56,64])                           -> float32[1,56,56,256]\n",
            "shortcut_batchnorm(float32[1,56,56,256], is_training=True)   -> float32[1,56,56,256]\n",
            "conv_0(float32[1,56,56,64])                                  -> float32[1,56,56,64]\n",
            "batchnorm_0(float32[1,56,56,64], is_training=True)           -> float32[1,56,56,64]\n",
            "conv_1(float32[1,56,56,64])                                  -> float32[1,56,56,64]\n",
            "batchnorm_1(float32[1,56,56,64], is_training=True)           -> float32[1,56,56,64]\n",
            "conv_2(float32[1,56,56,64])                                  -> float32[1,56,56,256]\n",
            "batchnorm_2(float32[1,56,56,256], is_training=True)          -> float32[1,56,56,256]\n",
            "block_0(float32[1,56,56,64], is_training=True)               -> float32[1,56,56,256]\n",
            "conv_0(float32[1,56,56,256])                                 -> float32[1,56,56,64]\n",
            "batchnorm_0(float32[1,56,56,64], is_training=True)           -> float32[1,56,56,64]\n",
            "conv_1(float32[1,56,56,64])                                  -> float32[1,56,56,64]\n",
            "batchnorm_1(float32[1,56,56,64], is_training=True)           -> float32[1,56,56,64]\n",
            "conv_2(float32[1,56,56,64])                                  -> float32[1,56,56,256]\n",
            "batchnorm_2(float32[1,56,56,256], is_training=True)          -> float32[1,56,56,256]\n",
            "block_1(float32[1,56,56,256], is_training=True)              -> float32[1,56,56,256]\n",
            "conv_0(float32[1,56,56,256])                                 -> float32[1,56,56,64]\n",
            "batchnorm_0(float32[1,56,56,64], is_training=True)           -> float32[1,56,56,64]\n",
            "conv_1(float32[1,56,56,64])                                  -> float32[1,56,56,64]\n",
            "batchnorm_1(float32[1,56,56,64], is_training=True)           -> float32[1,56,56,64]\n",
            "conv_2(float32[1,56,56,64])                                  -> float32[1,56,56,256]\n",
            "batchnorm_2(float32[1,56,56,256], is_training=True)          -> float32[1,56,56,256]\n",
            "block_2(float32[1,56,56,256], is_training=True)              -> float32[1,56,56,256]\n",
            "block_group_0(float32[1,56,56,64], True)                     -> float32[1,56,56,256]\n",
            "shortcut_conv(float32[1,56,56,256])                          -> float32[1,28,28,512]\n",
            "shortcut_batchnorm(float32[1,28,28,512], is_training=True)   -> float32[1,28,28,512]\n",
            "conv_0(float32[1,56,56,256])                                 -> float32[1,56,56,128]\n",
            "batchnorm_0(float32[1,56,56,128], is_training=True)          -> float32[1,56,56,128]\n",
            "conv_1(float32[1,56,56,128])                                 -> float32[1,28,28,128]\n",
            "batchnorm_1(float32[1,28,28,128], is_training=True)          -> float32[1,28,28,128]\n",
            "conv_2(float32[1,28,28,128])                                 -> float32[1,28,28,512]\n",
            "batchnorm_2(float32[1,28,28,512], is_training=True)          -> float32[1,28,28,512]\n",
            "block_0(float32[1,56,56,256], is_training=True)              -> float32[1,28,28,512]\n",
            "conv_0(float32[1,28,28,512])                                 -> float32[1,28,28,128]\n",
            "batchnorm_0(float32[1,28,28,128], is_training=True)          -> float32[1,28,28,128]\n",
            "conv_1(float32[1,28,28,128])                                 -> float32[1,28,28,128]\n",
            "batchnorm_1(float32[1,28,28,128], is_training=True)          -> float32[1,28,28,128]\n",
            "conv_2(float32[1,28,28,128])                                 -> float32[1,28,28,512]\n",
            "batchnorm_2(float32[1,28,28,512], is_training=True)          -> float32[1,28,28,512]\n",
            "block_1(float32[1,28,28,512], is_training=True)              -> float32[1,28,28,512]\n",
            "conv_0(float32[1,28,28,512])                                 -> float32[1,28,28,128]\n",
            "batchnorm_0(float32[1,28,28,128], is_training=True)          -> float32[1,28,28,128]\n",
            "conv_1(float32[1,28,28,128])                                 -> float32[1,28,28,128]\n",
            "batchnorm_1(float32[1,28,28,128], is_training=True)          -> float32[1,28,28,128]\n",
            "conv_2(float32[1,28,28,128])                                 -> float32[1,28,28,512]\n",
            "batchnorm_2(float32[1,28,28,512], is_training=True)          -> float32[1,28,28,512]\n",
            "block_2(float32[1,28,28,512], is_training=True)              -> float32[1,28,28,512]\n",
            "conv_0(float32[1,28,28,512])                                 -> float32[1,28,28,128]\n",
            "batchnorm_0(float32[1,28,28,128], is_training=True)          -> float32[1,28,28,128]\n",
            "conv_1(float32[1,28,28,128])                                 -> float32[1,28,28,128]\n",
            "batchnorm_1(float32[1,28,28,128], is_training=True)          -> float32[1,28,28,128]\n",
            "conv_2(float32[1,28,28,128])                                 -> float32[1,28,28,512]\n",
            "batchnorm_2(float32[1,28,28,512], is_training=True)          -> float32[1,28,28,512]\n",
            "block_3(float32[1,28,28,512], is_training=True)              -> float32[1,28,28,512]\n",
            "block_group_1(float32[1,56,56,256], True)                    -> float32[1,28,28,512]\n",
            "shortcut_conv(float32[1,28,28,512])                          -> float32[1,14,14,1024]\n",
            "shortcut_batchnorm(float32[1,14,14,1024], is_training=True)  -> float32[1,14,14,1024]\n",
            "conv_0(float32[1,28,28,512])                                 -> float32[1,28,28,256]\n",
            "batchnorm_0(float32[1,28,28,256], is_training=True)          -> float32[1,28,28,256]\n",
            "conv_1(float32[1,28,28,256])                                 -> float32[1,14,14,256]\n",
            "batchnorm_1(float32[1,14,14,256], is_training=True)          -> float32[1,14,14,256]\n",
            "conv_2(float32[1,14,14,256])                                 -> float32[1,14,14,1024]\n",
            "batchnorm_2(float32[1,14,14,1024], is_training=True)         -> float32[1,14,14,1024]\n",
            "block_0(float32[1,28,28,512], is_training=True)              -> float32[1,14,14,1024]\n",
            "conv_0(float32[1,14,14,1024])                                -> float32[1,14,14,256]\n",
            "batchnorm_0(float32[1,14,14,256], is_training=True)          -> float32[1,14,14,256]\n",
            "conv_1(float32[1,14,14,256])                                 -> float32[1,14,14,256]\n",
            "batchnorm_1(float32[1,14,14,256], is_training=True)          -> float32[1,14,14,256]\n",
            "conv_2(float32[1,14,14,256])                                 -> float32[1,14,14,1024]\n",
            "batchnorm_2(float32[1,14,14,1024], is_training=True)         -> float32[1,14,14,1024]\n",
            "block_1(float32[1,14,14,1024], is_training=True)             -> float32[1,14,14,1024]\n",
            "conv_0(float32[1,14,14,1024])                                -> float32[1,14,14,256]\n",
            "batchnorm_0(float32[1,14,14,256], is_training=True)          -> float32[1,14,14,256]\n",
            "conv_1(float32[1,14,14,256])                                 -> float32[1,14,14,256]\n",
            "batchnorm_1(float32[1,14,14,256], is_training=True)          -> float32[1,14,14,256]\n",
            "conv_2(float32[1,14,14,256])                                 -> float32[1,14,14,1024]\n",
            "batchnorm_2(float32[1,14,14,1024], is_training=True)         -> float32[1,14,14,1024]\n",
            "block_2(float32[1,14,14,1024], is_training=True)             -> float32[1,14,14,1024]\n",
            "conv_0(float32[1,14,14,1024])                                -> float32[1,14,14,256]\n",
            "batchnorm_0(float32[1,14,14,256], is_training=True)          -> float32[1,14,14,256]\n",
            "conv_1(float32[1,14,14,256])                                 -> float32[1,14,14,256]\n",
            "batchnorm_1(float32[1,14,14,256], is_training=True)          -> float32[1,14,14,256]\n",
            "conv_2(float32[1,14,14,256])                                 -> float32[1,14,14,1024]\n",
            "batchnorm_2(float32[1,14,14,1024], is_training=True)         -> float32[1,14,14,1024]\n",
            "block_3(float32[1,14,14,1024], is_training=True)             -> float32[1,14,14,1024]\n",
            "conv_0(float32[1,14,14,1024])                                -> float32[1,14,14,256]\n",
            "batchnorm_0(float32[1,14,14,256], is_training=True)          -> float32[1,14,14,256]\n",
            "conv_1(float32[1,14,14,256])                                 -> float32[1,14,14,256]\n",
            "batchnorm_1(float32[1,14,14,256], is_training=True)          -> float32[1,14,14,256]\n",
            "conv_2(float32[1,14,14,256])                                 -> float32[1,14,14,1024]\n",
            "batchnorm_2(float32[1,14,14,1024], is_training=True)         -> float32[1,14,14,1024]\n",
            "block_4(float32[1,14,14,1024], is_training=True)             -> float32[1,14,14,1024]\n",
            "conv_0(float32[1,14,14,1024])                                -> float32[1,14,14,256]\n",
            "batchnorm_0(float32[1,14,14,256], is_training=True)          -> float32[1,14,14,256]\n",
            "conv_1(float32[1,14,14,256])                                 -> float32[1,14,14,256]\n",
            "batchnorm_1(float32[1,14,14,256], is_training=True)          -> float32[1,14,14,256]\n",
            "conv_2(float32[1,14,14,256])                                 -> float32[1,14,14,1024]\n",
            "batchnorm_2(float32[1,14,14,1024], is_training=True)         -> float32[1,14,14,1024]\n",
            "block_5(float32[1,14,14,1024], is_training=True)             -> float32[1,14,14,1024]\n",
            "block_group_2(float32[1,28,28,512], True)                    -> float32[1,14,14,1024]\n",
            "shortcut_conv(float32[1,14,14,1024])                         -> float32[1,7,7,2048]\n",
            "shortcut_batchnorm(float32[1,7,7,2048], is_training=True)    -> float32[1,7,7,2048]\n",
            "conv_0(float32[1,14,14,1024])                                -> float32[1,14,14,512]\n",
            "batchnorm_0(float32[1,14,14,512], is_training=True)          -> float32[1,14,14,512]\n",
            "conv_1(float32[1,14,14,512])                                 -> float32[1,7,7,512]\n",
            "batchnorm_1(float32[1,7,7,512], is_training=True)            -> float32[1,7,7,512]\n",
            "conv_2(float32[1,7,7,512])                                   -> float32[1,7,7,2048]\n",
            "batchnorm_2(float32[1,7,7,2048], is_training=True)           -> float32[1,7,7,2048]\n",
            "block_0(float32[1,14,14,1024], is_training=True)             -> float32[1,7,7,2048]\n",
            "conv_0(float32[1,7,7,2048])                                  -> float32[1,7,7,512]\n",
            "batchnorm_0(float32[1,7,7,512], is_training=True)            -> float32[1,7,7,512]\n",
            "conv_1(float32[1,7,7,512])                                   -> float32[1,7,7,512]\n",
            "batchnorm_1(float32[1,7,7,512], is_training=True)            -> float32[1,7,7,512]\n",
            "conv_2(float32[1,7,7,512])                                   -> float32[1,7,7,2048]\n",
            "batchnorm_2(float32[1,7,7,2048], is_training=True)           -> float32[1,7,7,2048]\n",
            "block_1(float32[1,7,7,2048], is_training=True)               -> float32[1,7,7,2048]\n",
            "conv_0(float32[1,7,7,2048])                                  -> float32[1,7,7,512]\n",
            "batchnorm_0(float32[1,7,7,512], is_training=True)            -> float32[1,7,7,512]\n",
            "conv_1(float32[1,7,7,512])                                   -> float32[1,7,7,512]\n",
            "batchnorm_1(float32[1,7,7,512], is_training=True)            -> float32[1,7,7,512]\n",
            "conv_2(float32[1,7,7,512])                                   -> float32[1,7,7,2048]\n",
            "batchnorm_2(float32[1,7,7,2048], is_training=True)           -> float32[1,7,7,2048]\n",
            "block_2(float32[1,7,7,2048], is_training=True)               -> float32[1,7,7,2048]\n",
            "block_group_3(float32[1,14,14,1024], True)                   -> float32[1,7,7,2048]\n",
            "logits(float32[1,2048])                                      -> float32[1,1000]\n",
            "res_net50(float32[1,224,224,3], is_training=True)            -> float32[1,1000]\n"
          ]
        }
      ]
    }
  ]
}